{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Bedrock\n",
    "\n",
    "llm = Bedrock(\n",
    "    # credentials_profile_name=\"bedrock-admin\",\n",
    "    model_id=\"anthropic.claude-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hello! I'm Claude, an AI assistant created by Anthropic.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, verbose=True, memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "\n",
    "llm = Bedrock(\n",
    "    model_id=\"anthropic.claude-v2\",\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      " Hello! Nice to meet you. What would you like to talk about? I'm Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hello! Nice to meet you. What would you like to talk about? I'm Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, verbose=True, memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a simple explanation of black holes for 8th graders:\n",
      "\n",
      "- A black hole is a region in space where gravity is so strong that nothing can escape from it, even light. This region is called the event horizon.\n",
      "\n",
      "- Black holes form when very massive stars collapse under their own gravity at the end of their life cycle. This collapse crushes the mass of the star into a very small, dense region forming the black hole. \n",
      "\n",
      "- The gravity of a black hole is so intense because all of the mass of the collapsed star is concentrated into an extremely small space. This creates a gravitational field that is so strong that not even light can escape past the event horizon.\n",
      "\n",
      "- The event horizon is the boundary around the black hole where the escape velocity (the speed needed to break free from the gravitational pull) equals the speed of light (300,000 km/s). Nothing can go faster than the speed of light, so nothing can escape from inside the event horizon.\n",
      "\n",
      "- Black holes cannot be directly observed because they emit no light. But we can detect them by observing their gravitational effects on nearby stars and gas clouds. Large black holes also pull in and \"swallow\" nearby matter, producing a lot of X-ray radiation as the matter accelerates and heats up.\n",
      "\n",
      "- Supermassive black holes are thought to exist at the center of most large galaxies, including our own Milky Way galaxy. These black holes have masses millions\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "body = json.dumps({\n",
    "    \"prompt\": \"\\n\\nHuman:explain black holes to 8th graders\\n\\nAssistant:\",\n",
    "    \"max_tokens_to_sample\": 300,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.9,\n",
    "})\n",
    "\n",
    "modelId = 'anthropic.claude-v2'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "# text\n",
    "print(response_body.get('completion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'completion': ' Here', 'stop_reason': None}\n",
      "{'completion': ' is a 997 word essay on living on Mars:\\n\\nLife on', 'stop_reason': None}\n",
      "{'completion': ' Mars\\n\\nAs humanity expands beyond', 'stop_reason': None}\n",
      "{'completion': ' Earth, establishing a permanent human', 'stop_reason': None}\n",
      "{'completion': ' presence on Mars has become an exciting possibility', 'stop_reason': None}\n",
      "{'completion': '. While living on the red planet', 'stop_reason': None}\n",
      "{'completion': ' presents many challenges, it also offers opportunities for', 'stop_reason': None}\n",
      "{'completion': ' scientific discovery, technological innovation, and the future expansion', 'stop_reason': None}\n",
      "{'completion': ' of human civilization. \\n\\nThe journey to', 'stop_reason': None}\n",
      "{'completion': ' Mars itself will stretch the limits', 'stop_reason': None}\n",
      "{'completion': ' of', 'stop_reason': None}\n",
      "{'completion': ' human endurance. Future Martian explorers will endure months or years', 'stop_reason': None}\n",
      "{'completion': ' in a confined spacecraft, exposed to', 'stop_reason': 'max_tokens'}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "body = json.dumps({\n",
    "    'prompt': '\\n\\nHuman:write an essay for living on mars in 1000 words\\n\\nAssistant:',\n",
    "    'max_tokens_to_sample': 100\n",
    "})\n",
    "                   \n",
    "response = bedrock.invoke_model_with_response_stream(\n",
    "    modelId='anthropic.claude-v2', \n",
    "    body=body\n",
    ")\n",
    "    \n",
    "stream = response.get('body')\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        chunk = event.get('chunk')\n",
    "        if chunk:\n",
    "            print(json.loads(chunk.get('bytes').decode()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama-local-B1HCEK4S-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
