{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "config_list = [\n",
    "    {    \n",
    "        \"api_type\" : \"open_ai\",\n",
    "        # \"model\" : \"mistral-7b-instruct\",\n",
    "        # \"model\" : \"codellama-34b-instruct\",\n",
    "        \"model\" : \"llama-2-13b-chat\",\n",
    "        \"api_base\" : \"https://api.perplexity.ai\",\n",
    "        \"api_key\" : os.getenv(\"PPLX_API_KEY\")\n",
    "    }\n",
    "]\n",
    "\n",
    "llm_config = {\"config_list\": config_list, \"seed\" : 420}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Plot a chart of NVDA and TESLA stock price change YTD.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Sure, I'd be happy to help you with that! To plot a chart of NVDA and TESLA stock price change YTD, we'll need to use some Python code. Here's the script:\n",
      "# Filename: ytd_stock_chart.py\n",
      "import yfinance as yf\n",
      "# Get stock data for NVDA and TESLA\n",
      "nvda_data = yf.download('NVDA', start='2022-01-01')\n",
      "tesla_data = yf.download('TSLA', start='2022-01-01')\n",
      "# Calculate the year-to-date change for each stock\n",
      "nvda_ytd_change = nvda_data['Close'].pct_change()\n",
      "tesla_ytd_change = tesla_data['Close'].pct_change()\n",
      "# Plot the stock prices YTD\n",
      "import matplotlib.pyplot as plt\n",
      "plt.plot(nvda_ytd_change, label='NVDA')\n",
      "plt.plot(tesla_ytd_change, label='TSLA')\n",
      "plt.xlabel('Days')\n",
      "plt.ylabel('% Change')\n",
      "plt.title('Year-to-Date Stock Price Change for NVDA and TESLA')\n",
      "plt.legend()\n",
      "plt.show()\n",
      "\n",
      "This script uses the yfinance library to download the stock data for NVDA and TESLA, and then calculates the year-to-date change for each stock using the pct_change() function. Finally, it plots the stock prices YTD using Matplotlib.\n",
      "To execute this script, save it in a file with a .py extension (e.g., ytd_stock_chart.py) and then run it using Python's built-in IDLE or another IDE. The script will output a graph of the stock prices YTD for NVDA and TESLA.\n",
      "If you'd like to save the script in a file before executing it, you can save it as ytd_stock_chart.py and then run it using the command python ytd_stock_chart.py.\n",
      "Please let me know if you have any questions or if you'd like me to clarify any part of the script. Once you have the graph, you can analyze the year-to-date change for NVDA and TESLA and make any decisions based on that information.\n",
      "TERMINATE.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Hello! It looks like you've provided a prompt for a script or program, but you haven't specified what you would like the output to be. Can you please clarify what you would like the script to do and what the expected output should be? Please provide any additional information or details that might be helpful for me to know.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Sure, I'd be happy to help! Based on your prompt, it seems like you're looking for a script that will plot the year-to-date change for two stocks, NVDA and TSLA, using Matplotlib. Is that correct? If so, here's a simple script that should do what you're looking for:\n",
      "---\n",
      "import yfinance as yf\n",
      "# Get stock data for NVDA and TSLA\n",
      "nvda_data = yf.download('NVDA', start='2022-01-01')\n",
      "tesla_data = yf.download('TSLA', start='2022-01-01')\n",
      "# Calculate the year-to-date change for each stock\n",
      "nvda_ytd_change = nvda_data['Close'].pct_change()\n",
      "tesla_ytd_change = tesla_data['Close'].pct_change()\n",
      "# Plot the stock prices YTD\n",
      "import matplotlib.pyplot as plt\n",
      "plt.plot(nvda_ytd_change, label='NVDA')\n",
      "plt.plot(tesla_ytd_change, label='TSLA')\n",
      "plt.xlabel('Days')\n",
      "plt.ylabel('% Change')\n",
      "plt.title('Year-to-Date Stock Price Change for NVDA and TSLA')\n",
      "plt.legend()\n",
      "plt.show()\n",
      "\n",
      "---\n",
      "\n",
      "This script uses the yfinance library to download the stock data for NVDA and TSLA, and then calculates the year-to-date change for each stock using the pct_change() function. Finally, it plots the stock prices YTD using Matplotlib.\n",
      "If you'd like to run this script, you can save it to a file with a .py extension (e.g., ytd_stock_chart.py) and then run it using Python's built-in IDLE or another IDE. The script will output a graph of the stock prices YTD for NVDA and TSLA.\n",
      "Please let me know if you have any questions or if you'd like me to clarify any part of the script. I'm here to help!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "write the code to disk\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "To write the code to disk, you can use the `write()` method of the `ausmt` object. Here's an example of how you can do this:\n",
      "```\n",
      "# Write the code to a file called \" code.py\"\n",
      "ausmt.write(\"code.py\", code)\n",
      "\n",
      "```\n",
      "\n",
      "This will write the code to a file called \"code.py\" in the current working directory. If you want to write the code to a different file, you can specify the file path and name as arguments to the `write()` method, like this:\n",
      "```\n",
      "# Write the code to a file called \"my_code.py\" in the current working directory\n",
      "ausmt.write(\"my_code.py\", code)\n",
      "\n",
      "```\n",
      "\n",
      "Alternatively, you can use the `write_file()` method of the `ausmt` object to write the code to a file. Here's an example of how you can do this:\n",
      "```\n",
      "# Write the code to a file called \"code.py\" in the current working directory\n",
      "ausmt.write_file(\"code.py\", code)\n",
      "\n",
      "```\n",
      "\n",
      "This will write the code to a file called \"code.py\" in the current working directory, just like the `write()` method. However, the `write_file()` method allows you to specify additional options, such as the encoding and errors parameters, which can be useful if you need to write the code to a file with a specific encoding or errors handling.\n",
      "For example, to write the code to a file called \"code.py\" in the current working directory with an encoding of \"utf-8\", you can use the following code:\n",
      "```\n",
      "# Write the code to a file called \"code.py\" in the current working directory with an encoding of \"utf-8\"\n",
      "ausmt.write_file(\"code.py\", code, encoding=\"utf-8\")\n",
      "\n",
      "```\n",
      "\n",
      "I hope this helps! Let me know if you have any other questions.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n"
     ]
    },
    {
     "ename": "DockerException",
     "evalue": "Error while fetching server API version: ('Connection aborted.', PermissionError(13, 'Permission denied'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    792\u001b[0m     conn,\n\u001b[1;32m    793\u001b[0m     method,\n\u001b[1;32m    794\u001b[0m     url,\n\u001b[1;32m    795\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    796\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    797\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    798\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    799\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    800\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    801\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    802\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    803\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    804\u001b[0m )\n\u001b[1;32m    806\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:497\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     conn\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    498\u001b[0m         method,\n\u001b[1;32m    499\u001b[0m         url,\n\u001b[1;32m    500\u001b[0m         body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    501\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    502\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    503\u001b[0m         preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    504\u001b[0m         decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    505\u001b[0m         enforce_content_length\u001b[39m=\u001b[39;49menforce_content_length,\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    508\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/urllib3/connection.py:395\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 395\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders()\n\u001b[1;32m    397\u001b[0m \u001b[39m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/http/client.py:1281\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1281\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/http/client.py:1041\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1041\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m \n\u001b[1;32m   1045\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/http/client.py:979\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> 979\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    980\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/docker/transport/unixconn.py:27\u001b[0m, in \u001b[0;36mUnixHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m sock\u001b[39m.\u001b[39msettimeout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout)\n\u001b[0;32m---> 27\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munix_socket)\n\u001b[1;32m     28\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:845\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    843\u001b[0m     new_e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, new_e)\n\u001b[0;32m--> 845\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    846\u001b[0m     method, url, error\u001b[39m=\u001b[39;49mnew_e, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    847\u001b[0m )\n\u001b[1;32m    848\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/urllib3/util/retry.py:470\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 470\u001b[0m     \u001b[39mraise\u001b[39;00m reraise(\u001b[39mtype\u001b[39;49m(error), error, _stacktrace)\n\u001b[1;32m    471\u001b[0m \u001b[39melif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/urllib3/util/util.py:38\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m     39\u001b[0m \u001b[39mraise\u001b[39;00m value\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    792\u001b[0m     conn,\n\u001b[1;32m    793\u001b[0m     method,\n\u001b[1;32m    794\u001b[0m     url,\n\u001b[1;32m    795\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    796\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    797\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    798\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    799\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    800\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    801\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    802\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    803\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    804\u001b[0m )\n\u001b[1;32m    806\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:497\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     conn\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    498\u001b[0m         method,\n\u001b[1;32m    499\u001b[0m         url,\n\u001b[1;32m    500\u001b[0m         body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    501\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    502\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    503\u001b[0m         preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    504\u001b[0m         decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    505\u001b[0m         enforce_content_length\u001b[39m=\u001b[39;49menforce_content_length,\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    508\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/urllib3/connection.py:395\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 395\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders()\n\u001b[1;32m    397\u001b[0m \u001b[39m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/http/client.py:1281\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1281\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/http/client.py:1041\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1041\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m \n\u001b[1;32m   1045\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.11/lib/python3.11/http/client.py:979\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> 979\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    980\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/docker/transport/unixconn.py:27\u001b[0m, in \u001b[0;36mUnixHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m sock\u001b[39m.\u001b[39msettimeout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout)\n\u001b[0;32m---> 27\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munix_socket)\n\u001b[1;32m     28\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', PermissionError(13, 'Permission denied'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/docker/api/client.py:214\u001b[0m, in \u001b[0;36mAPIClient._retrieve_server_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 214\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mversion(api_version\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m\"\u001b[39m\u001b[39mApiVersion\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/docker/api/daemon.py:181\u001b[0m, in \u001b[0;36mDaemonApiMixin.version\u001b[0;34m(self, api_version)\u001b[0m\n\u001b[1;32m    180\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url(\u001b[39m\"\u001b[39m\u001b[39m/version\u001b[39m\u001b[39m\"\u001b[39m, versioned_api\u001b[39m=\u001b[39mapi_version)\n\u001b[0;32m--> 181\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get(url), json\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/docker/utils/decorators.py:46\u001b[0m, in \u001b[0;36mupdate_headers.<locals>.inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         kwargs[\u001b[39m'\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_general_configs[\u001b[39m'\u001b[39m\u001b[39mHttpHeaders\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 46\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/docker/api/client.py:237\u001b[0m, in \u001b[0;36mAPIClient._get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39m@update_headers\u001b[39m\n\u001b[1;32m    236\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get\u001b[39m(\u001b[39mself\u001b[39m, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget(url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_request_timeout(kwargs))\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/requests/adapters.py:501\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    503\u001b[0m \u001b[39mexcept\u001b[39;00m MaxRetryError \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectionError\u001b[0m: ('Connection aborted.', PermissionError(13, 'Permission denied'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDockerException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/tranqy/projects/ollama-play/autogen.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bwiggum/home/tranqy/projects/ollama-play/autogen.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m assistant \u001b[39m=\u001b[39m AssistantAgent(\u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, llm_config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mconfig_list\u001b[39m\u001b[39m\"\u001b[39m: config_list})\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bwiggum/home/tranqy/projects/ollama-play/autogen.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m user_proxy \u001b[39m=\u001b[39m UserProxyAgent(\u001b[39m\"\u001b[39m\u001b[39muser_proxy\u001b[39m\u001b[39m\"\u001b[39m, code_execution_config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mwork_dir\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcoding\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bwiggum/home/tranqy/projects/ollama-play/autogen.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m user_proxy\u001b[39m.\u001b[39;49minitiate_chat(assistant, message\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPlot a chart of NVDA and TESLA stock price change YTD.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:531\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \n\u001b[1;32m    519\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[0;32m--> 531\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:464\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_reply(messages\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchat_messages[sender], sender\u001b[39m=\u001b[39msender)\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(reply, sender, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:464\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_reply(messages\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchat_messages[sender], sender\u001b[39m=\u001b[39msender)\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(reply, sender, silent\u001b[39m=\u001b[39;49msilent)\n",
      "    \u001b[0;31m[... skipping similar frames: ConversableAgent.send at line 334 (5 times), ConversableAgent.receive at line 464 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:464\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_reply(messages\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchat_messages[sender], sender\u001b[39m=\u001b[39msender)\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(reply, sender, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:462\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:781\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    780\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[0;32m--> 781\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[1;32m    783\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:637\u001b[0m, in \u001b[0;36mConversableAgent.generate_code_execution_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[39m# found code blocks, execute code and push \"last_n_messages\" back\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m exitcode, logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute_code_blocks(code_blocks)\n\u001b[1;32m    638\u001b[0m code_execution_config[\u001b[39m\"\u001b[39m\u001b[39mlast_n_messages\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m last_n_messages\n\u001b[1;32m    639\u001b[0m exitcode2str \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mexecution succeeded\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m exitcode \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mexecution failed\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:908\u001b[0m, in \u001b[0;36mConversableAgent.execute_code_blocks\u001b[0;34m(self, code_blocks)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    907\u001b[0m         filename \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 908\u001b[0m     exitcode, logs, image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_code(\n\u001b[1;32m    909\u001b[0m         code,\n\u001b[1;32m    910\u001b[0m         lang\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpython\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    911\u001b[0m         filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[1;32m    912\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_code_execution_config,\n\u001b[1;32m    913\u001b[0m     )\n\u001b[1;32m    914\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    915\u001b[0m     \u001b[39m# In case the language is not supported, we return an error message.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m     exitcode, logs, image \u001b[39m=\u001b[39m (\n\u001b[1;32m    917\u001b[0m         \u001b[39m1\u001b[39m,\n\u001b[1;32m    918\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munknown language \u001b[39m\u001b[39m{\u001b[39;00mlang\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    919\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:885\u001b[0m, in \u001b[0;36mConversableAgent.run_code\u001b[0;34m(self, code, **kwargs)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_code\u001b[39m(\u001b[39mself\u001b[39m, code, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    872\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run the code and return the result.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \n\u001b[1;32m    874\u001b[0m \u001b[39m    Override this function to modify the way to run the code.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[39m        image (str or None): the docker image used for the code execution.\u001b[39;00m\n\u001b[1;32m    884\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 885\u001b[0m     \u001b[39mreturn\u001b[39;00m execute_code(code, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/autogen/code_utils.py:340\u001b[0m, in \u001b[0;36mexecute_code\u001b[0;34m(code, timeout, filename, work_dir, use_docker, lang)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mreturncode, logs, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[39m# create a docker client\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m client \u001b[39m=\u001b[39m docker\u001b[39m.\u001b[39;49mfrom_env()\n\u001b[1;32m    341\u001b[0m image_list \u001b[39m=\u001b[39m (\n\u001b[1;32m    342\u001b[0m     [\u001b[39m\"\u001b[39m\u001b[39mpython:3-alpine\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpython:3\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpython:3-windowsservercore\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    343\u001b[0m     \u001b[39mif\u001b[39;00m use_docker \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[39melse\u001b[39;00m use_docker\n\u001b[1;32m    347\u001b[0m )\n\u001b[1;32m    348\u001b[0m \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m image_list:\n\u001b[1;32m    349\u001b[0m     \u001b[39m# check if the image exists\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/docker/client.py:96\u001b[0m, in \u001b[0;36mDockerClient.from_env\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m version \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     95\u001b[0m use_ssh_client \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39muse_ssh_client\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 96\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m     97\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m     98\u001b[0m     max_pool_size\u001b[39m=\u001b[39;49mmax_pool_size,\n\u001b[1;32m     99\u001b[0m     version\u001b[39m=\u001b[39;49mversion,\n\u001b[1;32m    100\u001b[0m     use_ssh_client\u001b[39m=\u001b[39;49muse_ssh_client,\n\u001b[1;32m    101\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs_from_env(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    102\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/docker/client.py:45\u001b[0m, in \u001b[0;36mDockerClient.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi \u001b[39m=\u001b[39m APIClient(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/docker/api/client.py:197\u001b[0m, in \u001b[0;36mAPIClient.__init__\u001b[0;34m(self, base_url, version, timeout, tls, user_agent, num_pools, credstore_env, use_ssh_client, max_pool_size)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39m# version detection needs to be after unix adapter mounting\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[39mif\u001b[39;00m version \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(\n\u001b[1;32m    194\u001b[0m                         version,\n\u001b[1;32m    195\u001b[0m                         \u001b[39mstr\u001b[39m\n\u001b[1;32m    196\u001b[0m                         ) \u001b[39mand\u001b[39;00m version\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 197\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_version \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retrieve_server_version()\n\u001b[1;32m    198\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_version \u001b[39m=\u001b[39m version\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ollama-local--MYF8Ucm-py3.11/lib/python3.11/site-packages/docker/api/client.py:221\u001b[0m, in \u001b[0;36mAPIClient._retrieve_server_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[39mraise\u001b[39;00m DockerException(\n\u001b[1;32m    217\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mInvalid response from docker daemon: key \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mApiVersion\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m is missing.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    219\u001b[0m     )\n\u001b[1;32m    220\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m DockerException(\n\u001b[1;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mError while fetching server API version: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    223\u001b[0m     )\n",
      "\u001b[0;31mDockerException\u001b[0m: Error while fetching server API version: ('Connection aborted.', PermissionError(13, 'Permission denied'))"
     ]
    }
   ],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent, config_list_from_json\n",
    "\n",
    "assistant = AssistantAgent(\"assistant\", llm_config={\"config_list\": config_list})\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", code_execution_config={\"work_dir\": \"coding\"})\n",
    "user_proxy.initiate_chat(assistant, message=\"Plot a chart of NVDA and TESLA stock price change YTD.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama-local--MYF8Ucm-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
